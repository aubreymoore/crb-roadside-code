{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exposed-mediterranean",
   "metadata": {},
   "source": [
    "# extract_gps_data.ipynb\n",
    "\n",
    "* 2023-04-09 Timestamp extracted from image filename instead of EXIF. An attempt to fix infrequent errors (2 out of 20000) in timestamp provided by EXIF\n",
    "* 2022-12-03 Added error handling for when no image files are found\n",
    "* 2022-09-04 Added error handling code which deletes images from which gps coordinates cannot be extracted\n",
    "* 2021-11-20 Fixed problems in get_gps_coordinates()\n",
    "* 2021-05-06 Added code to adjust coordinates using rolling averages\n",
    "* 2021-05-02 First version by Aubrey Moore\n",
    "\n",
    "Extracts geotagging data from EXIF tags stored in one or more image files.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "    papermill extract_gps_data.ipynb \\\n",
    "    '../output/extract_gps_data_output.ipynb' \\\n",
    "    -p IMAGE_FILE_PATH '../rawdata/*.jpg' \\\n",
    "    -p CSV_OUTPUT_FILE '../rawdata/gps-data.csv'\n",
    "    \n",
    "When the above command line is executed in the directory containing **extract_gps_data.ipynb**, \n",
    "GPS data will be extracted from all **jpg** files in the **IMAGE_FILE_PATH** and results will be saved in \n",
    "**CSV_OUTPUT_FILE**.\n",
    "\n",
    "\n",
    "2022-09-03T05:46:57+1000 [ERROR] create_dataframe Could not get gps coordinates from ../rawdata/IMG_20220221_112311.jpg; image ignored\n",
    "\n",
    "## References\n",
    "\n",
    "https://developer.here.com/blog/getting-started-with-geocoding-exif-image-metadata-in-python3\n",
    "\n",
    "http://www.50northspatial.org/using-open-camera-geotagging-photos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technological-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smaller-lesbian",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters for papermill\n",
    "\n",
    "IMAGE_FILE_PATH = '../rawdata/*.jpg'         # Path to one or more image files. Can include wildcards. See https://pymotw.com/2/glob/ for pattern matching details.\n",
    "CSV_OUTPUT_FILE = '../rawdata/gps-data.csv'  # Path to a CSV file where the GPS data will be stored. \n",
    "ADJUST_COORDINATES = True\n",
    "MAKE_MAPS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "taken-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exif(filename):\n",
    "    image = Image.open(filename)\n",
    "    image.verify()\n",
    "    return image._getexif()\n",
    "\n",
    "\n",
    "def get_geotagging(exif):\n",
    "    if not exif:\n",
    "        raise ValueError(\"No EXIF metadata found\")\n",
    "    geotagging = {}\n",
    "    for (idx, tag) in TAGS.items():\n",
    "        if tag == 'GPSInfo':\n",
    "            if idx not in exif:\n",
    "                raise ValueError(\"No EXIF geotagging found\")\n",
    "            for (key, val) in GPSTAGS.items():\n",
    "                if key in exif[idx]:\n",
    "                    geotagging[val] = exif[idx][key]\n",
    "    return geotagging\n",
    "\n",
    "\n",
    "def get_gps_coordinates(image_file_name):\n",
    "    exif = get_exif(image_file_name)\n",
    "    gpsdata = get_geotagging(exif)\n",
    "        \n",
    "    d,m,s = gpsdata['GPSLatitude']\n",
    "    latitude = d + m/60.0 + s/3600.0\n",
    "    if gpsdata['GPSLatitudeRef']=='S':\n",
    "        latitude = -latitude\n",
    "    latitude = round(latitude, 6)\n",
    "\n",
    "    d,m,s = gpsdata['GPSLongitude']\n",
    "    longitude = d + m/60.0 + s/3600.0\n",
    "    if gpsdata['GPSLongitudeRef']=='W':\n",
    "        longitude = -longitude\n",
    "    longitude = round(longitude, 6)\n",
    "    \n",
    "# # Get timestamp from EXIF data    \n",
    "#     date = gpsdata['GPSDateStamp']\n",
    "#     date = date.replace(':', '-')\n",
    "#     h, m, s = gpsdata['GPSTimeStamp']\n",
    "#     timestamp = f'{date} {int(h):02}:{int(m):02}:{int(s):02}'\n",
    "\n",
    "    # get timestamp from filename\n",
    "    timestamp = os.path.basename(image_file_name).replace('IMG_', '').replace('.jpg', '')\n",
    "    timestamp = pd.to_datetime(timestamp, format='%Y%m%d_%H%M%S')\n",
    "    \n",
    "    return longitude, latitude, timestamp\n",
    "\n",
    "def create_dataframe():\n",
    "    # Get a sorted list of image files\n",
    "    image_files = sorted(glob.glob(IMAGE_FILE_PATH))\n",
    "    n = len(image_files)\n",
    "    \n",
    "    if n == 0:\n",
    "        raise Exception(f\"No image files were found in {IMAGE_FILE_PATH}\")\n",
    "\n",
    "    # Extract coordinates from each image file\n",
    "    df = pd.DataFrame(columns=['imagefile','longitude','latitude','timestamp'])\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        try:\n",
    "            longitude, latitude, timestamp = get_gps_coordinates(image_file)\n",
    "            df = df.append({'imagefile':os.path.basename(image_file),\n",
    "                            'longitude':longitude,\n",
    "                            'latitude':latitude,\n",
    "                            'timestamp':pd.to_datetime(timestamp)}, ignore_index=True) \n",
    "        except:\n",
    "#            os.remove(image_file) # WAY TOO RISKY. WHAT WAS I THINKING?\n",
    "            logging.error(f'Could not get gps coordinates from {image_file}; image deleted')\n",
    "        \n",
    "        if ((i+1) % 100 == 0):\n",
    "            logging.info(f'{i+1} of {n} images processed')\n",
    "                \n",
    "    return df \n",
    "\n",
    "\n",
    "def adjust_gps_coordinates():\n",
    "    '''\n",
    "    Calculates rolling averages for latitude and longitude to get better estimates for camera \n",
    "    positions and saves them in new columns: longitude_adjusted and latitude_adjusted. \n",
    "    This is a work-a-round for low precision GPS EXIF data data saved by the \n",
    "    OpenCamera app. For some reason, the app saves only degrees, minutes and seconds without decimal places. \n",
    "    This notebook calculates new points using 5-point rolling averages of latitude and longitude. \n",
    "    '''\n",
    "    df['time_diff'] = df[\"timestamp\"].diff().apply(lambda x: x/np.timedelta64(1,'s')).fillna(0).astype('int64')\n",
    "    \n",
    "    # Find location of segment breaks\n",
    "    # A new segment begins when an (image is taken is more than 60s after previous image\n",
    "\n",
    "    segments = []\n",
    "    segment_breaks = df.index[df['time_diff'] > 60].tolist()\n",
    "    segment_breaks.append(df.shape[0]) # Last index plus 1\n",
    "    for i, segment_break in enumerate(segment_breaks):\n",
    "        if i == 0:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = segment_breaks[i-1]\n",
    "        segments.append({'first_index': start, 'last_index': segment_break-1})\n",
    "    logging.info(f'segments: {segments}')\n",
    "\n",
    "    # Calculate rolling averages to locations within each segment\n",
    "           \n",
    "    for segment in segments:\n",
    "        i1 = segment['first_index']\n",
    "        i2 = segment['last_index']\n",
    "        df.loc[i1:i2, 'longitude_adjusted'] = df.loc[i1:i2, 'longitude'].rolling(5, center=True, min_periods=1).mean() \n",
    "        df.loc[i1:i2, 'latitude_adjusted'] = df.loc[i1:i2, 'latitude'].rolling(5, center=True, min_periods=1).mean() \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "taken-version",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09T17:28:01+1000 [INFO] <module> Starting georef.py\n",
      "2023-04-09T17:28:02+1000 [INFO] create_dataframe 100 of 22273 images processed\n",
      "2023-04-09T17:28:02+1000 [INFO] create_dataframe 200 of 22273 images processed\n",
      "2023-04-09T17:28:02+1000 [INFO] create_dataframe 300 of 22273 images processed\n",
      "2023-04-09T17:28:03+1000 [INFO] create_dataframe 400 of 22273 images processed\n",
      "2023-04-09T17:28:03+1000 [INFO] create_dataframe 500 of 22273 images processed\n",
      "2023-04-09T17:28:03+1000 [INFO] create_dataframe 600 of 22273 images processed\n",
      "2023-04-09T17:28:04+1000 [INFO] create_dataframe 700 of 22273 images processed\n",
      "2023-04-09T17:28:04+1000 [INFO] create_dataframe 800 of 22273 images processed\n",
      "2023-04-09T17:28:04+1000 [INFO] create_dataframe 900 of 22273 images processed\n",
      "2023-04-09T17:28:04+1000 [INFO] create_dataframe 1000 of 22273 images processed\n",
      "2023-04-09T17:28:05+1000 [INFO] create_dataframe 1100 of 22273 images processed\n",
      "2023-04-09T17:28:05+1000 [INFO] create_dataframe 1200 of 22273 images processed\n",
      "2023-04-09T17:28:05+1000 [INFO] create_dataframe 1300 of 22273 images processed\n",
      "2023-04-09T17:28:06+1000 [INFO] create_dataframe 1400 of 22273 images processed\n",
      "2023-04-09T17:28:06+1000 [INFO] create_dataframe 1500 of 22273 images processed\n",
      "2023-04-09T17:28:06+1000 [INFO] create_dataframe 1600 of 22273 images processed\n",
      "2023-04-09T17:28:07+1000 [INFO] create_dataframe 1700 of 22273 images processed\n",
      "2023-04-09T17:28:07+1000 [INFO] create_dataframe 1800 of 22273 images processed\n",
      "2023-04-09T17:28:07+1000 [INFO] create_dataframe 1900 of 22273 images processed\n",
      "2023-04-09T17:28:08+1000 [INFO] create_dataframe 2000 of 22273 images processed\n",
      "2023-04-09T17:28:08+1000 [INFO] create_dataframe 2100 of 22273 images processed\n",
      "2023-04-09T17:28:08+1000 [INFO] create_dataframe 2200 of 22273 images processed\n",
      "2023-04-09T17:28:09+1000 [INFO] create_dataframe 2300 of 22273 images processed\n",
      "2023-04-09T17:28:09+1000 [INFO] create_dataframe 2400 of 22273 images processed\n",
      "2023-04-09T17:28:09+1000 [INFO] create_dataframe 2500 of 22273 images processed\n",
      "2023-04-09T17:28:10+1000 [INFO] create_dataframe 2600 of 22273 images processed\n",
      "2023-04-09T17:28:10+1000 [INFO] create_dataframe 2700 of 22273 images processed\n",
      "2023-04-09T17:28:10+1000 [INFO] create_dataframe 2800 of 22273 images processed\n",
      "2023-04-09T17:28:10+1000 [INFO] create_dataframe 2900 of 22273 images processed\n",
      "2023-04-09T17:28:11+1000 [INFO] create_dataframe 3000 of 22273 images processed\n",
      "2023-04-09T17:28:11+1000 [INFO] create_dataframe 3100 of 22273 images processed\n",
      "2023-04-09T17:28:11+1000 [INFO] create_dataframe 3200 of 22273 images processed\n",
      "2023-04-09T17:28:12+1000 [INFO] create_dataframe 3300 of 22273 images processed\n",
      "2023-04-09T17:28:12+1000 [INFO] create_dataframe 3400 of 22273 images processed\n",
      "2023-04-09T17:28:12+1000 [INFO] create_dataframe 3500 of 22273 images processed\n",
      "2023-04-09T17:28:13+1000 [INFO] create_dataframe 3600 of 22273 images processed\n",
      "2023-04-09T17:28:13+1000 [INFO] create_dataframe 3700 of 22273 images processed\n",
      "2023-04-09T17:28:13+1000 [INFO] create_dataframe 3800 of 22273 images processed\n",
      "2023-04-09T17:28:13+1000 [INFO] create_dataframe 3900 of 22273 images processed\n",
      "2023-04-09T17:28:14+1000 [INFO] create_dataframe 4000 of 22273 images processed\n",
      "2023-04-09T17:28:14+1000 [INFO] create_dataframe 4100 of 22273 images processed\n",
      "2023-04-09T17:28:14+1000 [INFO] create_dataframe 4200 of 22273 images processed\n",
      "2023-04-09T17:28:15+1000 [INFO] create_dataframe 4300 of 22273 images processed\n",
      "2023-04-09T17:28:15+1000 [INFO] create_dataframe 4400 of 22273 images processed\n",
      "2023-04-09T17:28:15+1000 [INFO] create_dataframe 4500 of 22273 images processed\n",
      "2023-04-09T17:28:16+1000 [INFO] create_dataframe 4600 of 22273 images processed\n",
      "2023-04-09T17:28:16+1000 [INFO] create_dataframe 4700 of 22273 images processed\n",
      "2023-04-09T17:28:16+1000 [INFO] create_dataframe 4800 of 22273 images processed\n",
      "2023-04-09T17:28:17+1000 [INFO] create_dataframe 4900 of 22273 images processed\n",
      "2023-04-09T17:28:17+1000 [INFO] create_dataframe 5000 of 22273 images processed\n",
      "2023-04-09T17:28:17+1000 [INFO] create_dataframe 5100 of 22273 images processed\n",
      "2023-04-09T17:28:17+1000 [INFO] create_dataframe 5200 of 22273 images processed\n",
      "2023-04-09T17:28:18+1000 [INFO] create_dataframe 5300 of 22273 images processed\n",
      "2023-04-09T17:28:18+1000 [INFO] create_dataframe 5400 of 22273 images processed\n",
      "2023-04-09T17:28:18+1000 [INFO] create_dataframe 5500 of 22273 images processed\n",
      "2023-04-09T17:28:19+1000 [INFO] create_dataframe 5600 of 22273 images processed\n",
      "2023-04-09T17:28:19+1000 [INFO] create_dataframe 5700 of 22273 images processed\n",
      "2023-04-09T17:28:19+1000 [INFO] create_dataframe 5800 of 22273 images processed\n",
      "2023-04-09T17:28:20+1000 [INFO] create_dataframe 5900 of 22273 images processed\n",
      "2023-04-09T17:28:20+1000 [INFO] create_dataframe 6000 of 22273 images processed\n",
      "2023-04-09T17:28:20+1000 [INFO] create_dataframe 6100 of 22273 images processed\n",
      "2023-04-09T17:28:21+1000 [INFO] create_dataframe 6200 of 22273 images processed\n",
      "2023-04-09T17:28:21+1000 [INFO] create_dataframe 6300 of 22273 images processed\n",
      "2023-04-09T17:28:21+1000 [INFO] create_dataframe 6400 of 22273 images processed\n",
      "2023-04-09T17:28:22+1000 [INFO] create_dataframe 6500 of 22273 images processed\n",
      "2023-04-09T17:28:22+1000 [INFO] create_dataframe 6600 of 22273 images processed\n",
      "2023-04-09T17:28:22+1000 [INFO] create_dataframe 6700 of 22273 images processed\n",
      "2023-04-09T17:28:23+1000 [INFO] create_dataframe 6800 of 22273 images processed\n",
      "2023-04-09T17:28:23+1000 [INFO] create_dataframe 6900 of 22273 images processed\n",
      "2023-04-09T17:28:23+1000 [INFO] create_dataframe 7000 of 22273 images processed\n",
      "2023-04-09T17:28:23+1000 [INFO] create_dataframe 7100 of 22273 images processed\n",
      "2023-04-09T17:28:24+1000 [INFO] create_dataframe 7200 of 22273 images processed\n",
      "2023-04-09T17:28:24+1000 [INFO] create_dataframe 7300 of 22273 images processed\n",
      "2023-04-09T17:28:24+1000 [INFO] create_dataframe 7400 of 22273 images processed\n",
      "2023-04-09T17:28:25+1000 [INFO] create_dataframe 7500 of 22273 images processed\n",
      "2023-04-09T17:28:25+1000 [INFO] create_dataframe 7600 of 22273 images processed\n",
      "2023-04-09T17:28:25+1000 [INFO] create_dataframe 7700 of 22273 images processed\n",
      "2023-04-09T17:28:26+1000 [INFO] create_dataframe 7800 of 22273 images processed\n",
      "2023-04-09T17:28:26+1000 [INFO] create_dataframe 7900 of 22273 images processed\n",
      "2023-04-09T17:28:26+1000 [INFO] create_dataframe 8000 of 22273 images processed\n",
      "2023-04-09T17:28:27+1000 [INFO] create_dataframe 8100 of 22273 images processed\n",
      "2023-04-09T17:28:27+1000 [INFO] create_dataframe 8200 of 22273 images processed\n",
      "2023-04-09T17:28:27+1000 [INFO] create_dataframe 8300 of 22273 images processed\n",
      "2023-04-09T17:28:27+1000 [INFO] create_dataframe 8400 of 22273 images processed\n",
      "2023-04-09T17:28:28+1000 [INFO] create_dataframe 8500 of 22273 images processed\n",
      "2023-04-09T17:28:28+1000 [INFO] create_dataframe 8600 of 22273 images processed\n",
      "2023-04-09T17:28:28+1000 [INFO] create_dataframe 8700 of 22273 images processed\n",
      "2023-04-09T17:28:29+1000 [INFO] create_dataframe 8800 of 22273 images processed\n",
      "2023-04-09T17:28:29+1000 [INFO] create_dataframe 8900 of 22273 images processed\n",
      "2023-04-09T17:28:29+1000 [INFO] create_dataframe 9000 of 22273 images processed\n",
      "2023-04-09T17:28:30+1000 [INFO] create_dataframe 9100 of 22273 images processed\n",
      "2023-04-09T17:28:30+1000 [INFO] create_dataframe 9200 of 22273 images processed\n",
      "2023-04-09T17:28:30+1000 [INFO] create_dataframe 9300 of 22273 images processed\n",
      "2023-04-09T17:28:31+1000 [INFO] create_dataframe 9400 of 22273 images processed\n",
      "2023-04-09T17:28:31+1000 [INFO] create_dataframe 9500 of 22273 images processed\n",
      "2023-04-09T17:28:31+1000 [INFO] create_dataframe 9600 of 22273 images processed\n",
      "2023-04-09T17:28:32+1000 [INFO] create_dataframe 9700 of 22273 images processed\n",
      "2023-04-09T17:28:32+1000 [INFO] create_dataframe 9800 of 22273 images processed\n",
      "2023-04-09T17:28:32+1000 [INFO] create_dataframe 9900 of 22273 images processed\n",
      "2023-04-09T17:28:32+1000 [INFO] create_dataframe 10000 of 22273 images processed\n",
      "2023-04-09T17:28:33+1000 [INFO] create_dataframe 10100 of 22273 images processed\n",
      "2023-04-09T17:28:33+1000 [INFO] create_dataframe 10200 of 22273 images processed\n",
      "2023-04-09T17:28:33+1000 [INFO] create_dataframe 10300 of 22273 images processed\n",
      "2023-04-09T17:28:34+1000 [INFO] create_dataframe 10400 of 22273 images processed\n",
      "2023-04-09T17:28:34+1000 [INFO] create_dataframe 10500 of 22273 images processed\n",
      "2023-04-09T17:28:34+1000 [INFO] create_dataframe 10600 of 22273 images processed\n",
      "2023-04-09T17:28:35+1000 [INFO] create_dataframe 10700 of 22273 images processed\n",
      "2023-04-09T17:28:35+1000 [INFO] create_dataframe 10800 of 22273 images processed\n",
      "2023-04-09T17:28:35+1000 [INFO] create_dataframe 10900 of 22273 images processed\n",
      "2023-04-09T17:28:36+1000 [INFO] create_dataframe 11000 of 22273 images processed\n",
      "2023-04-09T17:28:36+1000 [INFO] create_dataframe 11100 of 22273 images processed\n",
      "2023-04-09T17:28:36+1000 [INFO] create_dataframe 11200 of 22273 images processed\n",
      "2023-04-09T17:28:37+1000 [INFO] create_dataframe 11300 of 22273 images processed\n",
      "2023-04-09T17:28:37+1000 [INFO] create_dataframe 11400 of 22273 images processed\n",
      "2023-04-09T17:28:37+1000 [INFO] create_dataframe 11500 of 22273 images processed\n",
      "2023-04-09T17:28:38+1000 [INFO] create_dataframe 11600 of 22273 images processed\n",
      "2023-04-09T17:28:38+1000 [INFO] create_dataframe 11700 of 22273 images processed\n",
      "2023-04-09T17:28:38+1000 [INFO] create_dataframe 11800 of 22273 images processed\n",
      "2023-04-09T17:28:39+1000 [INFO] create_dataframe 11900 of 22273 images processed\n",
      "2023-04-09T17:28:39+1000 [INFO] create_dataframe 12000 of 22273 images processed\n",
      "2023-04-09T17:28:39+1000 [INFO] create_dataframe 12100 of 22273 images processed\n",
      "2023-04-09T17:28:40+1000 [INFO] create_dataframe 12200 of 22273 images processed\n",
      "2023-04-09T17:28:40+1000 [INFO] create_dataframe 12300 of 22273 images processed\n",
      "2023-04-09T17:28:40+1000 [INFO] create_dataframe 12400 of 22273 images processed\n",
      "2023-04-09T17:28:41+1000 [INFO] create_dataframe 12500 of 22273 images processed\n",
      "2023-04-09T17:28:41+1000 [INFO] create_dataframe 12600 of 22273 images processed\n",
      "2023-04-09T17:28:41+1000 [INFO] create_dataframe 12700 of 22273 images processed\n",
      "2023-04-09T17:28:41+1000 [INFO] create_dataframe 12800 of 22273 images processed\n",
      "2023-04-09T17:28:42+1000 [INFO] create_dataframe 12900 of 22273 images processed\n",
      "2023-04-09T17:28:42+1000 [INFO] create_dataframe 13000 of 22273 images processed\n",
      "2023-04-09T17:28:42+1000 [INFO] create_dataframe 13100 of 22273 images processed\n",
      "2023-04-09T17:28:43+1000 [INFO] create_dataframe 13200 of 22273 images processed\n",
      "2023-04-09T17:28:43+1000 [INFO] create_dataframe 13300 of 22273 images processed\n",
      "2023-04-09T17:28:43+1000 [INFO] create_dataframe 13400 of 22273 images processed\n",
      "2023-04-09T17:28:44+1000 [INFO] create_dataframe 13500 of 22273 images processed\n",
      "2023-04-09T17:28:44+1000 [INFO] create_dataframe 13600 of 22273 images processed\n",
      "2023-04-09T17:28:44+1000 [INFO] create_dataframe 13700 of 22273 images processed\n",
      "2023-04-09T17:28:45+1000 [INFO] create_dataframe 13800 of 22273 images processed\n",
      "2023-04-09T17:28:45+1000 [INFO] create_dataframe 13900 of 22273 images processed\n",
      "2023-04-09T17:28:45+1000 [INFO] create_dataframe 14000 of 22273 images processed\n",
      "2023-04-09T17:28:45+1000 [INFO] create_dataframe 14100 of 22273 images processed\n",
      "2023-04-09T17:28:46+1000 [INFO] create_dataframe 14200 of 22273 images processed\n",
      "2023-04-09T17:28:46+1000 [INFO] create_dataframe 14300 of 22273 images processed\n",
      "2023-04-09T17:28:46+1000 [INFO] create_dataframe 14400 of 22273 images processed\n",
      "2023-04-09T17:28:47+1000 [INFO] create_dataframe 14500 of 22273 images processed\n",
      "2023-04-09T17:28:47+1000 [INFO] create_dataframe 14600 of 22273 images processed\n",
      "2023-04-09T17:28:47+1000 [INFO] create_dataframe 14700 of 22273 images processed\n",
      "2023-04-09T17:28:48+1000 [INFO] create_dataframe 14800 of 22273 images processed\n",
      "2023-04-09T17:28:48+1000 [INFO] create_dataframe 14900 of 22273 images processed\n",
      "2023-04-09T17:28:48+1000 [INFO] create_dataframe 15000 of 22273 images processed\n",
      "2023-04-09T17:28:49+1000 [INFO] create_dataframe 15100 of 22273 images processed\n",
      "2023-04-09T17:28:49+1000 [INFO] create_dataframe 15200 of 22273 images processed\n",
      "2023-04-09T17:28:49+1000 [INFO] create_dataframe 15300 of 22273 images processed\n",
      "2023-04-09T17:28:50+1000 [INFO] create_dataframe 15400 of 22273 images processed\n",
      "2023-04-09T17:28:50+1000 [INFO] create_dataframe 15500 of 22273 images processed\n",
      "2023-04-09T17:28:50+1000 [INFO] create_dataframe 15600 of 22273 images processed\n",
      "2023-04-09T17:28:51+1000 [INFO] create_dataframe 15700 of 22273 images processed\n",
      "2023-04-09T17:28:51+1000 [INFO] create_dataframe 15800 of 22273 images processed\n",
      "2023-04-09T17:28:51+1000 [INFO] create_dataframe 15900 of 22273 images processed\n",
      "2023-04-09T17:28:52+1000 [INFO] create_dataframe 16000 of 22273 images processed\n",
      "2023-04-09T17:28:52+1000 [INFO] create_dataframe 16100 of 22273 images processed\n",
      "2023-04-09T17:28:52+1000 [INFO] create_dataframe 16200 of 22273 images processed\n",
      "2023-04-09T17:28:53+1000 [INFO] create_dataframe 16300 of 22273 images processed\n",
      "2023-04-09T17:28:53+1000 [INFO] create_dataframe 16400 of 22273 images processed\n",
      "2023-04-09T17:28:53+1000 [INFO] create_dataframe 16500 of 22273 images processed\n",
      "2023-04-09T17:28:54+1000 [INFO] create_dataframe 16600 of 22273 images processed\n",
      "2023-04-09T17:28:54+1000 [INFO] create_dataframe 16700 of 22273 images processed\n",
      "2023-04-09T17:28:54+1000 [INFO] create_dataframe 16800 of 22273 images processed\n",
      "2023-04-09T17:28:55+1000 [INFO] create_dataframe 16900 of 22273 images processed\n",
      "2023-04-09T17:28:55+1000 [INFO] create_dataframe 17000 of 22273 images processed\n",
      "2023-04-09T17:28:55+1000 [INFO] create_dataframe 17100 of 22273 images processed\n",
      "2023-04-09T17:28:56+1000 [INFO] create_dataframe 17200 of 22273 images processed\n",
      "2023-04-09T17:28:56+1000 [INFO] create_dataframe 17300 of 22273 images processed\n",
      "2023-04-09T17:28:56+1000 [INFO] create_dataframe 17400 of 22273 images processed\n",
      "2023-04-09T17:28:56+1000 [INFO] create_dataframe 17500 of 22273 images processed\n",
      "2023-04-09T17:28:57+1000 [INFO] create_dataframe 17600 of 22273 images processed\n",
      "2023-04-09T17:28:57+1000 [INFO] create_dataframe 17700 of 22273 images processed\n",
      "2023-04-09T17:28:57+1000 [INFO] create_dataframe 17800 of 22273 images processed\n",
      "2023-04-09T17:28:58+1000 [INFO] create_dataframe 17900 of 22273 images processed\n",
      "2023-04-09T17:28:58+1000 [INFO] create_dataframe 18000 of 22273 images processed\n",
      "2023-04-09T17:28:58+1000 [INFO] create_dataframe 18100 of 22273 images processed\n",
      "2023-04-09T17:28:59+1000 [INFO] create_dataframe 18200 of 22273 images processed\n",
      "2023-04-09T17:28:59+1000 [INFO] create_dataframe 18300 of 22273 images processed\n",
      "2023-04-09T17:28:59+1000 [INFO] create_dataframe 18400 of 22273 images processed\n",
      "2023-04-09T17:29:00+1000 [INFO] create_dataframe 18500 of 22273 images processed\n",
      "2023-04-09T17:29:00+1000 [INFO] create_dataframe 18600 of 22273 images processed\n",
      "2023-04-09T17:29:00+1000 [INFO] create_dataframe 18700 of 22273 images processed\n",
      "2023-04-09T17:29:01+1000 [INFO] create_dataframe 18800 of 22273 images processed\n",
      "2023-04-09T17:29:01+1000 [INFO] create_dataframe 18900 of 22273 images processed\n",
      "2023-04-09T17:29:01+1000 [INFO] create_dataframe 19000 of 22273 images processed\n",
      "2023-04-09T17:29:02+1000 [INFO] create_dataframe 19100 of 22273 images processed\n",
      "2023-04-09T17:29:02+1000 [INFO] create_dataframe 19200 of 22273 images processed\n",
      "2023-04-09T17:29:02+1000 [INFO] create_dataframe 19300 of 22273 images processed\n",
      "2023-04-09T17:29:03+1000 [INFO] create_dataframe 19400 of 22273 images processed\n",
      "2023-04-09T17:29:03+1000 [INFO] create_dataframe 19500 of 22273 images processed\n",
      "2023-04-09T17:29:03+1000 [INFO] create_dataframe 19600 of 22273 images processed\n",
      "2023-04-09T17:29:04+1000 [INFO] create_dataframe 19700 of 22273 images processed\n",
      "2023-04-09T17:29:04+1000 [INFO] create_dataframe 19800 of 22273 images processed\n",
      "2023-04-09T17:29:04+1000 [INFO] create_dataframe 19900 of 22273 images processed\n",
      "2023-04-09T17:29:05+1000 [INFO] create_dataframe 20000 of 22273 images processed\n",
      "2023-04-09T17:29:05+1000 [INFO] create_dataframe 20100 of 22273 images processed\n",
      "2023-04-09T17:29:05+1000 [INFO] create_dataframe 20200 of 22273 images processed\n",
      "2023-04-09T17:29:05+1000 [INFO] create_dataframe 20300 of 22273 images processed\n",
      "2023-04-09T17:29:06+1000 [INFO] create_dataframe 20400 of 22273 images processed\n",
      "2023-04-09T17:29:06+1000 [INFO] create_dataframe 20500 of 22273 images processed\n",
      "2023-04-09T17:29:06+1000 [INFO] create_dataframe 20600 of 22273 images processed\n",
      "2023-04-09T17:29:07+1000 [INFO] create_dataframe 20700 of 22273 images processed\n",
      "2023-04-09T17:29:07+1000 [INFO] create_dataframe 20800 of 22273 images processed\n",
      "2023-04-09T17:29:07+1000 [INFO] create_dataframe 20900 of 22273 images processed\n",
      "2023-04-09T17:29:08+1000 [INFO] create_dataframe 21000 of 22273 images processed\n",
      "2023-04-09T17:29:08+1000 [INFO] create_dataframe 21100 of 22273 images processed\n",
      "2023-04-09T17:29:08+1000 [INFO] create_dataframe 21200 of 22273 images processed\n",
      "2023-04-09T17:29:09+1000 [INFO] create_dataframe 21300 of 22273 images processed\n",
      "2023-04-09T17:29:09+1000 [INFO] create_dataframe 21400 of 22273 images processed\n",
      "2023-04-09T17:29:09+1000 [INFO] create_dataframe 21500 of 22273 images processed\n",
      "2023-04-09T17:29:10+1000 [INFO] create_dataframe 21600 of 22273 images processed\n",
      "2023-04-09T17:29:10+1000 [INFO] create_dataframe 21700 of 22273 images processed\n",
      "2023-04-09T17:29:10+1000 [INFO] create_dataframe 21800 of 22273 images processed\n",
      "2023-04-09T17:29:11+1000 [INFO] create_dataframe 21900 of 22273 images processed\n",
      "2023-04-09T17:29:11+1000 [INFO] create_dataframe 22000 of 22273 images processed\n",
      "2023-04-09T17:29:11+1000 [INFO] create_dataframe 22100 of 22273 images processed\n",
      "2023-04-09T17:29:12+1000 [INFO] create_dataframe 22200 of 22273 images processed\n",
      "2023-04-09T17:29:12+1000 [INFO] <module> Adjusting coordinates\n",
      "2023-04-09T17:29:12+1000 [INFO] adjust_gps_coordinates segments: [{'first_index': 0, 'last_index': 865}, {'first_index': 866, 'last_index': 1641}, {'first_index': 1642, 'last_index': 6387}, {'first_index': 6388, 'last_index': 8602}, {'first_index': 8603, 'last_index': 8610}, {'first_index': 8611, 'last_index': 8614}, {'first_index': 8615, 'last_index': 8624}, {'first_index': 8625, 'last_index': 8628}, {'first_index': 8629, 'last_index': 13392}, {'first_index': 13393, 'last_index': 22272}]\n",
      "2023-04-09T17:29:12+1000 [INFO] <module> FINISHED: Data saved in ../rawdata/gps-data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 670 ms, total: 1min 10s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# MAIN\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(funcName)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%dT%H:%M:%S%z\",\n",
    "    handlers=[logging.StreamHandler()])\n",
    "logging.info('Starting georef.py')\n",
    "\n",
    "df = create_dataframe()\n",
    "\n",
    "if ADJUST_COORDINATES:\n",
    "    logging.info('Adjusting coordinates')\n",
    "    adjust_gps_coordinates()\n",
    "    \n",
    "df.to_csv(CSV_OUTPUT_FILE, index=False)\n",
    "logging.info(f'FINISHED: Data saved in {CSV_OUTPUT_FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interim-bangkok",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagefile</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>longitude_adjusted</th>\n",
       "      <th>latitude_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_20230403_102010.jpg</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "      <td>2023-04-03 10:20:10</td>\n",
       "      <td>0</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_20230403_102011.jpg</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "      <td>2023-04-03 10:20:11</td>\n",
       "      <td>1</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_20230403_102012.jpg</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "      <td>2023-04-03 10:20:12</td>\n",
       "      <td>1</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_20230403_102013.jpg</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "      <td>2023-04-03 10:20:13</td>\n",
       "      <td>1</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_20230403_102015.jpg</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "      <td>2023-04-03 10:20:15</td>\n",
       "      <td>2</td>\n",
       "      <td>144.800278</td>\n",
       "      <td>13.431111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22268</th>\n",
       "      <td>IMG_20230407_170443.jpg</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "      <td>2023-04-07 17:04:43</td>\n",
       "      <td>1</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22269</th>\n",
       "      <td>IMG_20230407_170444.jpg</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "      <td>2023-04-07 17:04:44</td>\n",
       "      <td>1</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22270</th>\n",
       "      <td>IMG_20230407_170446.jpg</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "      <td>2023-04-07 17:04:46</td>\n",
       "      <td>2</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22271</th>\n",
       "      <td>IMG_20230407_170447.jpg</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "      <td>2023-04-07 17:04:47</td>\n",
       "      <td>1</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22272</th>\n",
       "      <td>IMG_20230407_170448.jpg</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "      <td>2023-04-07 17:04:48</td>\n",
       "      <td>1</td>\n",
       "      <td>144.851667</td>\n",
       "      <td>13.486944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22273 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     imagefile   longitude   latitude           timestamp  \\\n",
       "0      IMG_20230403_102010.jpg  144.800278  13.431111 2023-04-03 10:20:10   \n",
       "1      IMG_20230403_102011.jpg  144.800278  13.431111 2023-04-03 10:20:11   \n",
       "2      IMG_20230403_102012.jpg  144.800278  13.431111 2023-04-03 10:20:12   \n",
       "3      IMG_20230403_102013.jpg  144.800278  13.431111 2023-04-03 10:20:13   \n",
       "4      IMG_20230403_102015.jpg  144.800278  13.431111 2023-04-03 10:20:15   \n",
       "...                        ...         ...        ...                 ...   \n",
       "22268  IMG_20230407_170443.jpg  144.851667  13.486944 2023-04-07 17:04:43   \n",
       "22269  IMG_20230407_170444.jpg  144.851667  13.486944 2023-04-07 17:04:44   \n",
       "22270  IMG_20230407_170446.jpg  144.851667  13.486944 2023-04-07 17:04:46   \n",
       "22271  IMG_20230407_170447.jpg  144.851667  13.486944 2023-04-07 17:04:47   \n",
       "22272  IMG_20230407_170448.jpg  144.851667  13.486944 2023-04-07 17:04:48   \n",
       "\n",
       "       time_diff  longitude_adjusted  latitude_adjusted  \n",
       "0              0          144.800278          13.431111  \n",
       "1              1          144.800278          13.431111  \n",
       "2              1          144.800278          13.431111  \n",
       "3              1          144.800278          13.431111  \n",
       "4              2          144.800278          13.431111  \n",
       "...          ...                 ...                ...  \n",
       "22268          1          144.851667          13.486944  \n",
       "22269          1          144.851667          13.486944  \n",
       "22270          2          144.851667          13.486944  \n",
       "22271          1          144.851667          13.486944  \n",
       "22272          1          144.851667          13.486944  \n",
       "\n",
       "[22273 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "headed-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_MAPS:\n",
    "    fig = px.scatter_mapbox(df, lat=\"latitude\", lon=\"longitude\", title='Original coordinates', zoom=9)\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\", margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smoking-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MAKE_MAPS and ADJUST_COORDINATES:\n",
    "    fig = px.scatter_mapbox(df, lat=\"latitude_adjusted\", lon=\"longitude_adjusted\", \n",
    "                            title='Adjusted coordinates', zoom=9)\n",
    "    fig.update_layout(mapbox_style=\"open-street-map\", margin={\"r\":0,\"t\":30,\"l\":0,\"b\":0})\n",
    "    fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "loved-receptor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-04-03 10:20:10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "preceding-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-04-07 17:04:48')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.timestamp.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
