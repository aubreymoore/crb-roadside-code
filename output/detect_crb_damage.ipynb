{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "previous-fifteen",
   "metadata": {
    "papermill": {
     "duration": 0.021761,
     "end_time": "2023-05-21T05:38:37.535133",
     "exception": false,
     "start_time": "2023-05-21T05:38:37.513372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# detect_crb_damage.ipynb\n",
    "\n",
    "**If a ResourceExhausteError is returned when firing up the GPU, this can usually be handled by restarting the machine.**\n",
    "\n",
    "* 2021-05-02 First version by Aubrey Moore\n",
    "\n",
    "This notebook uses a pair of Tensorflow object detectors to measure coconut rhinoceros beetle damage in digital images.\n",
    "\n",
    "Example usage:\n",
    "\n",
    "    papermill detect_crb_damage.ipynb \\\n",
    "     '../open-camera-test/home-uog/detect_crb_damage_output.ipynb' \\\n",
    "    -p IMAGE_FILE_PATH '../rawdata/*.jpg' \\\n",
    "    -p OUTPUT_XML_PATH '../output/detected_objects.xml'\n",
    "\n",
    "When the above command line is executed in the directory containing **detect_crb_damage.ipynb**, \n",
    "all **jpg** image files in the **IMAGE_FILE_PATH** directory will be scanned by the\n",
    "object detectors and results will be saved in **OUTPUT_XML_PATH**.\n",
    "\n",
    "2022-07-23 Added MAX_IMAGES for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "saved-canon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:37.568795Z",
     "iopub.status.busy": "2023-05-21T05:38:37.568333Z",
     "iopub.status.idle": "2023-05-21T05:38:38.669386Z",
     "shell.execute_reply": "2023-05-21T05:38:38.669063Z"
    },
    "papermill": {
     "duration": 1.117129,
     "end_time": "2023-05-21T05:38:38.669477",
     "exception": false,
     "start_time": "2023-05-21T05:38:37.552348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aubreytensor1/.local/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/aubreytensor1/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# import tensorflow as tf\n",
    "# uncomment following lines if you are using TF2\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "about-restaurant",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:38.685300Z",
     "iopub.status.busy": "2023-05-21T05:38:38.684946Z",
     "iopub.status.idle": "2023-05-21T05:38:39.142753Z",
     "shell.execute_reply": "2023-05-21T05:38:39.142468Z"
    },
    "papermill": {
     "duration": 0.467724,
     "end_time": "2023-05-21T05:38:39.142841",
     "exception": false,
     "start_time": "2023-05-21T05:38:38.675117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import ast\n",
    "import cv2\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.append('Mask_RCNN')\n",
    "from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "from xml_dumper import dump_as_cvat_annotation\n",
    "import skimage.io\n",
    "from collections import OrderedDict\n",
    "from skimage.measure import find_contours, approximate_polygon\n",
    "import glob\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "median-adaptation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:39.158257Z",
     "iopub.status.busy": "2023-05-21T05:38:39.157817Z",
     "iopub.status.idle": "2023-05-21T05:38:39.160257Z",
     "shell.execute_reply": "2023-05-21T05:38:39.159925Z"
    },
    "papermill": {
     "duration": 0.012234,
     "end_time": "2023-05-21T05:38:39.160332",
     "exception": false,
     "start_time": "2023-05-21T05:38:39.148098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "criminal-africa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:39.173779Z",
     "iopub.status.busy": "2023-05-21T05:38:39.173450Z",
     "iopub.status.idle": "2023-05-21T05:38:39.175793Z",
     "shell.execute_reply": "2023-05-21T05:38:39.176079Z"
    },
    "papermill": {
     "duration": 0.01053,
     "end_time": "2023-05-21T05:38:39.176167",
     "exception": false,
     "start_time": "2023-05-21T05:38:39.165637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 µs (started: 2023-05-21 15:38:39 +10:00)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "competent-review",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:39.189879Z",
     "iopub.status.busy": "2023-05-21T05:38:39.189499Z",
     "iopub.status.idle": "2023-05-21T05:38:39.191653Z",
     "shell.execute_reply": "2023-05-21T05:38:39.191318Z"
    },
    "papermill": {
     "duration": 0.010006,
     "end_time": "2023-05-21T05:38:39.191729",
     "exception": false,
     "start_time": "2023-05-21T05:38:39.181723",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 610 µs (started: 2023-05-21 15:38:39 +10:00)\n"
     ]
    }
   ],
   "source": [
    "# parameters for papermill\n",
    "\n",
    "IMAGE_FILE_PATH = '../rawdata/*.jpg' # Path to one or more image files. Can include wildcards. See https://pymotw.com/2/glob/ for pattern matching details.\n",
    "OUTPUT_XML_PATH = '../output/detected_objects.xml' # Path to output file which will contain metadata for detected objects.\n",
    "MAX_IMAGES = 1000000  # maximum number of images to be processed\n",
    "\n",
    "TYPE = 'both' # what type of models to use [both,classes,v_shape]\n",
    "#SKIP_NO = 1 # int, num of frames to skip (must be >0)\n",
    "#NUM_FRAMES = None # how many frames to consider?\n",
    "OD_MODEL = \"object-detectors/inference_data/frozen_inference_graph_5classes.pb\" # path to trained detection model\n",
    "CLASSES_CVAT = \"object-detectors/inference_data/5classes.csv\" # classes you want to use for cvat, see readme for more details.\n",
    "CLASSES_TYPE = \"od\" # type of classes csv file [od, maskrcnn]\n",
    "MASK_MODEL =  \"object-detectors/inference_data/mask_rcnn_cvat_0160.h5\" # path to trained maskrcnn model\n",
    "OD_THRESHOLD = 0.5 # threshold for IoU\n",
    "MASK_THRESHOLD = 0.5 # threshold for maskrcnn\n",
    "#SURVEY_TYPE = \"v_shape\" # what to write in geojson [v_shape,classes]\n",
    "TASK_ID = 0 # required only if you want to use this in cvat\n",
    "TASK_NAME = \"demo\" # required only if you want to use this in cvat\n",
    "DUMP_SQL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compatible-protection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:39.205271Z",
     "iopub.status.busy": "2023-05-21T05:38:39.204926Z",
     "iopub.status.idle": "2023-05-21T05:38:39.207168Z",
     "shell.execute_reply": "2023-05-21T05:38:39.206831Z"
    },
    "papermill": {
     "duration": 0.009606,
     "end_time": "2023-05-21T05:38:39.207247",
     "exception": false,
     "start_time": "2023-05-21T05:38:39.197641",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 192 µs (started: 2023-05-21 15:38:39 +10:00)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "MAX_IMAGES = 1000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "about-ecuador",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:39.238608Z",
     "iopub.status.busy": "2023-05-21T05:38:39.238229Z",
     "iopub.status.idle": "2023-05-21T05:38:39.239896Z",
     "shell.execute_reply": "2023-05-21T05:38:39.240155Z"
    },
    "papermill": {
     "duration": 0.026963,
     "end_time": "2023-05-21T05:38:39.240245",
     "exception": false,
     "start_time": "2023-05-21T05:38:39.213282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.63 ms (started: 2023-05-21 15:38:39 +10:00)\n"
     ]
    }
   ],
   "source": [
    "class ObjectDetection:\n",
    "    def __init__(self, model_path):\n",
    "        self.detection_graph = tf.Graph()\n",
    "        with self.detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(model_path , 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "                config = tf.ConfigProto()\n",
    "                config.gpu_options.allow_growth=True\n",
    "                self.sess = tf.Session(graph=self.detection_graph, config=config)\n",
    "\n",
    "    def get_detections(self, image_np_expanded):\n",
    "        image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        (boxes, scores, classes, num_detections) = self.sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n",
    "        return boxes, scores, classes, num_detections\n",
    "\n",
    "    @staticmethod\n",
    "    def process_boxes(boxes, scores, classes, labels_mapping, threshold, width, height):\n",
    "        result = {}\n",
    "        for i in range(len(classes[0])):\n",
    "            if classes[0][i] in labels_mapping.keys():\n",
    "                if scores[0][i] >= threshold:\n",
    "                    xmin = int(boxes[0][i][1] * width)\n",
    "                    ymin = int(boxes[0][i][0] * height)\n",
    "                    xmax = int(boxes[0][i][3] * width)\n",
    "                    ymax = int(boxes[0][i][2] * height)\n",
    "                    label = labels_mapping[classes[0][i]]\n",
    "                    if label not in result:\n",
    "                        result[label] = []\n",
    "                    result[label].append([xmin,ymin,xmax,ymax])\n",
    "        return result\n",
    "\n",
    "class Segmentation:\n",
    "    def __init__(self, model_path, num_c=2):\n",
    "        class InferenceConfig(Config):\n",
    "            # Set batch size to 1 since we'll be running inference on\n",
    "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "            NAME = \"cvat\"\n",
    "            GPU_COUNT = 1\n",
    "            IMAGES_PER_GPU = 1\n",
    "            NUM_CLASSES = num_c\n",
    "\n",
    "        config = InferenceConfig()\n",
    "        #config.display()\n",
    "\n",
    "        # Create model object in inference mode.\n",
    "        self.model = modellib.MaskRCNN(mode=\"inference\", model_dir=\"./output\", config=config)\n",
    "        # Load weights trained on MS-COCO\n",
    "        self.model.load_weights(model_path, by_name=True)\n",
    "        self.labels_mapping = {0:'BG', 1:'cut'}\n",
    "\n",
    "    def get_polygons(self, images, threshold):\n",
    "        res = self.model.detect(images)\n",
    "        result = {}\n",
    "        for r in res:\n",
    "            for index, c_id in enumerate(r['class_ids']):\n",
    "                if c_id in self.labels_mapping.keys():\n",
    "                    if r['scores'][index] >= threshold:\n",
    "                        mask = r['masks'][:,:,index].astype(np.uint8)\n",
    "                        contours = find_contours(mask, 0.5)\n",
    "\n",
    "                        # KLUDGE\n",
    "                        # Handles a rare \"list index out of range error\" for contours[0]\n",
    "                        # If the contours array is empty, a dummy contour consisting of\n",
    "                        # the top left pisxel is provided.\n",
    "\n",
    "                        if not contours:\n",
    "                            print('ERROR: contour list is empty.')\n",
    "                            contour = np.array([[1.0,1.0],[1.0,0.0],[0.0,0.0],[0.0,1.0],[1.0,1.0]])\n",
    "                        else:\n",
    "                            contour = contours[0]\n",
    "                            # print(f'contour ({type(contour)}): {contour}')\n",
    "\n",
    "                        # end of KLUDGE\n",
    "\n",
    "                        contour = np.flip(contour, axis=1)\n",
    "                        contour = approximate_polygon(contour, tolerance=2.5)\n",
    "                        segmentation = contour.ravel().tolist()\n",
    "                        label = self.labels_mapping[c_id]\n",
    "                        if label not in result:\n",
    "                            result[label] = []\n",
    "                        result[label].append(segmentation)\n",
    "        return result\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def process_polygons(polygons, boxes):\n",
    "        \"\"\"\n",
    "           Check if any point of the polygon falls into any of coconot palms except for dead/non_recoverable.\n",
    "        \"\"\"\n",
    "        def _check_inside_boxes(polygon, boxes):\n",
    "            for point in polygon:\n",
    "                for label, bxes in boxes.items():\n",
    "                    for box in bxes:\n",
    "                        if point[0] > box[0] and point[0] < box[2] and point[1] > box[1] and point[1] < box[3] and label not in ['dead','non_recoverable']:\n",
    "                            # point is inside rectangle\n",
    "                            return True\n",
    "            return False\n",
    "\n",
    "        result = {}\n",
    "        for label_m, polys in polygons.items():\n",
    "            for polygon in polys:\n",
    "                p = [polygon[i:i+2] for i in range(0, len(polygon),2)]\n",
    "                if _check_inside_boxes(p, boxes):\n",
    "                    if label_m not in result:\n",
    "                        result[label_m] = []\n",
    "                    result[label_m].append(polygon)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def load_image_into_numpy(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def draw_instances(frame, boxes, masks):\n",
    "    colors = {'zero':(0,255,0), 'light':(0,0,255),'medium':(255,0,0),'high':(120,120,0),'non_recoverable':(0,120,120),'cut':(0,0,0)}\n",
    "    #draw boxes\n",
    "    for label, bxes in boxes.items():\n",
    "        for box in bxes:\n",
    "            cv2.rectangle(frame, (box[0],box[1]), (box[2],box[3]), colors[label], 5)\n",
    "    #draw polygons\n",
    "    for label, polygons in masks.items():\n",
    "        for polygon in polygons:\n",
    "            p = [polygon[i:i+2] for i in range(0, len(polygon),2)]\n",
    "            pts = np.array(p, np.int32)\n",
    "            pts = pts.reshape((-1,1,2))\n",
    "            cv2.polylines(frame, [pts], True, (0,255,255),5)\n",
    "    return frame\n",
    "\n",
    "def get_labels(classes_csv, type=\"od\"):\n",
    "    labels = []\n",
    "    with open(classes_csv, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "        # slogger.glob.info(\"class file data {}\".format(data))\n",
    "        for line in data[1:]:\n",
    "            if type == \"maskrcnn\":\n",
    "                if \",\" not in line:\n",
    "                    continue\n",
    "                # slogger.glob.info(\"classes line {}\".format(line))\n",
    "                label, num = line.strip().split(',')\n",
    "                labels.append(('label', [('name', line.strip())]))\n",
    "            else:\n",
    "                if \"label\" not in line:\n",
    "                    labels.append(('label', [('name', line.strip())]))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "whole-constitution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:39.255444Z",
     "iopub.status.busy": "2023-05-21T05:38:39.255106Z",
     "iopub.status.idle": "2023-05-21T05:38:39.257163Z",
     "shell.execute_reply": "2023-05-21T05:38:39.256834Z"
    },
    "papermill": {
     "duration": 0.01053,
     "end_time": "2023-05-21T05:38:39.257240",
     "exception": false,
     "start_time": "2023-05-21T05:38:39.246710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 431 µs (started: 2023-05-21 15:38:39 +10:00)\n"
     ]
    }
   ],
   "source": [
    "def merge_file_parts(target_file_path):\n",
    "    '''\n",
    "    This function reassembles a file from parts created with the \"split\" command.\n",
    "    Large files (> 40MB) are split so that they can be stored in GitHub repos.\n",
    "    Note that \"split\" is a Linux command. Not sure what the Windows equivalent is.\n",
    "    '''\n",
    "    if not os.path.isfile(target_file_path):\n",
    "        commandline = f'cat {target_file_path}.part_?? > {target_file_path}'\n",
    "        logging.info(f'Rebuilding {target_file_path}')\n",
    "        os.system(commandline)\n",
    "        \n",
    "# merge_file_parts('object-detectors/inference_data/frozen_inference_graph_5classes.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rotary-weather",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-21T05:38:39.279914Z",
     "iopub.status.busy": "2023-05-21T05:38:39.279549Z",
     "iopub.status.idle": "2023-05-21T05:40:24.458868Z",
     "shell.execute_reply": "2023-05-21T05:40:24.459313Z"
    },
    "papermill": {
     "duration": 105.195543,
     "end_time": "2023-05-21T05:40:24.459461",
     "exception": false,
     "start_time": "2023-05-21T05:38:39.263918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:39+1000 [INFO] <module> Starting detect_crb_damage.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:39+1000 [INFO] merge_file_parts Rebuilding object-detectors/inference_data/mask_rcnn_cvat_0160.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:39+1000 [INFO] merge_file_parts Rebuilding object-detectors/inference_data/frozen_inference_graph_5classes.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:40+1000 [WARNING] __getattr__ From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:43+1000 [WARNING] __getattr__ From Mask_RCNN/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From Mask_RCNN/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:43+1000 [WARNING] new_func From Mask_RCNN/mrcnn/model.py:399: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:43+1000 [WARNING] new_func From Mask_RCNN/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:43+1000 [WARNING] __getattr__ From Mask_RCNN/mrcnn/model.py:720: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:43+1000 [WARNING] __getattr__ From Mask_RCNN/mrcnn/model.py:722: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:43+1000 [WARNING] new_func From Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21T15:38:48+1000 [WARNING] __getattr__ From /usr/lib/python3/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n",
      "time: 1min 45s (started: 2023-05-21 15:38:39 +10:00)\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# Initialization\n",
    "################\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(funcName)s %(message)s\",\n",
    "    datefmt=\"%Y-%m-%dT%H:%M:%S%z\",\n",
    "    handlers=[logging.StreamHandler()])\n",
    "logging.info('Starting detect_crb_damage.ipynb')\n",
    "\n",
    "# Rebuild object-detectors/inference_data/mask_rcnn_cvat_0160.h5\n",
    "# from parts files if necessary\n",
    "\n",
    "merge_file_parts('object-detectors/inference_data/mask_rcnn_cvat_0160.h5')\n",
    "\n",
    "# Rebuild object-detectors/inference_data/frozen_inference_graph_5classes.pb \n",
    "# from parts files if necessary\n",
    "\n",
    "merge_file_parts('object-detectors/inference_data/frozen_inference_graph_5classes.pb')\n",
    "\n",
    "# Get a sorted list of image files\n",
    "\n",
    "image_files = sorted(glob.glob(IMAGE_FILE_PATH))\n",
    "num_frames = len(image_files)\n",
    "\n",
    "labels_from_csv = get_labels(CLASSES_CVAT, CLASSES_TYPE)\n",
    "\n",
    "# Intialize other variables\n",
    "\n",
    "final_result = {'meta':{'task': OrderedDict([('id',str(TASK_ID)),\n",
    "                                             ('name',str(TASK_NAME)),\n",
    "                                             ('size',str(num_frames)),\n",
    "                                             ('mode','interpolation'),\n",
    "                                             ('start_frame', str(0)),\n",
    "                                             ('stop_frame', str(num_frames-1)),\n",
    "                                             ('z_order',\"False\"),\n",
    "                                             ('labels', labels_from_csv)])},\n",
    "                'frames':[]}\n",
    "\n",
    "if TYPE == \"both\":\n",
    "    od_model = ObjectDetection(OD_MODEL)\n",
    "    seg_model = Segmentation(MASK_MODEL)\n",
    "elif TYPE == \"classes\":\n",
    "    od_model = ObjectDetection(OD_MODEL)\n",
    "elif TYPE == \"v_shape\":\n",
    "    seg_model = Segmentation(MASK_MODEL)\n",
    "    \n",
    "labels_mapping_od = {1:'zero',2:'light',3:'medium',4:'high',5:'non_recoverable'}\n",
    "\n",
    "# Get size of first image in list. It is assumed that all images are the same size.\n",
    "\n",
    "frame = cv2.imread(image_files[0])\n",
    "frame_height, frame_width, channels = frame.shape\n",
    "\n",
    "height, width = frame_height, frame_width\n",
    "\n",
    "# Process image files\n",
    "#####################\n",
    "\n",
    "frame_no = 0\n",
    "for image_file in image_files[0:MAX_IMAGES]:\n",
    "    frame_no += 1\n",
    "#     print(f'Image {frame_no} of {num_frames}')\n",
    "    frame = cv2.imread(image_file)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image_np_expanded = np.expand_dims(img, axis=0)\n",
    "\n",
    "    od_result = {}\n",
    "    result = {}\n",
    "    if TYPE == \"both\" or TYPE == \"classes\":\n",
    "        # run detection\n",
    "        boxes, scores, classes, num_detections = od_model.get_detections(image_np_expanded)\n",
    "        #normalize bounding boxes, also apply threshold\n",
    "        od_result = ObjectDetection.process_boxes(boxes, scores, classes, labels_mapping_od, OD_THRESHOLD, width, height)\n",
    "        if od_result:\n",
    "            #print(\"od\", od_result)\n",
    "            shapes = []\n",
    "            for label, boxes in od_result.items():\n",
    "                for box in boxes:\n",
    "                    shapes.append({'type':'rectangle','label':label,'occluded':0,'points':box})\n",
    "            final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "    if TYPE == \"both\" or TYPE == \"v_shape\":\n",
    "        # run segmentation\n",
    "        result = seg_model.get_polygons([img], MASK_THRESHOLD)\n",
    "        #print(\"Result before processing: \", result)\n",
    "        if TYPE == \"both\" or TYPE == \"classes\":\n",
    "            # filter out false positives if boxes are available\n",
    "            result = Segmentation.process_polygons(result, od_result)\n",
    "            #print(\"Result after processing: \", result)\n",
    "        if result:\n",
    "            shapes = []\n",
    "            for label, polygons in result.items():\n",
    "                for polygon in polygons:\n",
    "                    shapes.append({'type':'polygon','label':label,'occluded':0,'points':polygon})\n",
    "            frame_exists = False\n",
    "            for frame_ in final_result['frames']:\n",
    "                if frame_['frame'] == frame_no:\n",
    "                    break\n",
    "            if frame_exists:\n",
    "                final_result['frames']['shapes'].extend(shapes)\n",
    "            else:\n",
    "                final_result['frames'].append({'frame':frame_no, 'width':frame_width, 'height':frame_height, 'shapes':shapes})\n",
    "        if (frame_no % 100 == 0):\n",
    "            logging.info(f'Image {frame_no} of {num_frames}')\n",
    "                        \n",
    "#frame = draw_instances(frame, od_result, result)\n",
    "dump_as_cvat_annotation(open(OUTPUT_XML_PATH, \"w\"), final_result)\n",
    "\n",
    "print('FINISHED')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 109.03721,
   "end_time": "2023-05-21T05:40:25.807179",
   "environment_variables": {},
   "exception": null,
   "input_path": "detect_crb_damage.ipynb",
   "output_path": "../output/detect_crb_damage.ipynb",
   "parameters": {
    "MAX_IMAGES": 1000000
   },
   "start_time": "2023-05-21T05:38:36.769969",
   "version": "2.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}